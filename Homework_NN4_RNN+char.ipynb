{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1o0UfubJ91ZvE60NuCKhAxMe9X0SeNkIN","timestamp":1678521990290}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"in0PyicHhZDG","executionInfo":{"status":"ok","timestamp":1678537617590,"user_tz":-300,"elapsed":1397,"user":{"displayName":"Бот Nas","userId":"15068011115912218898"}}},"outputs":[],"source":["import datetime\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","\n","import pandas as pd\n","from itertools import product\n","from IPython.display import clear_output"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"73ieMA485Tme","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678537621159,"user_tz":-300,"elapsed":2535,"user":{"displayName":"Бот Nas","userId":"15068011115912218898"}},"outputId":"0376a23b-1092-4ced-80fc-3f5f88f9fc8f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["data_dir = 'drive/My Drive/'\n","train_lang = 'en'"],"metadata":{"id":"Os4tVkvmkTIp","executionInfo":{"status":"ok","timestamp":1678537622021,"user_tz":-300,"elapsed":13,"user":{"displayName":"Бот Nas","userId":"15068011115912218898"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class DatasetSeq(Dataset):\n","    def __init__(self, data_dir, train_lang='en'):\n","\t#open file\n","        with open(data_dir + train_lang + '.train', 'r') as f:\n","            train = f.read().split('\\n\\n')\n","\n","        # delete extra tag markup\n","        train = [x for x in train if not '_ ' in x]\n","\t    #init vocabs of tokens for encoding {<str> token: <int> id}\n","        self.target_vocab = {} # {p: 1, a: 2, r: 3, pu: 4}\n","        self.word_vocab = {} # {cat: 1, sat: 2, on: 3, mat: 4, '.': 5}\n","        self.char_vocab = {} # {c: 1, a: 2, t: 3, ' ': 4, s: 5}\n","\t    \n","        # Cat sat on mat. -> [1, 2, 3, 4, 5]\n","        # p    a  r  p pu -> [1, 2, 3, 1, 4]\n","        # chars  -> [1, 2, 3, 4, 5, 2, 3, 4]\n","\n","\t    #init encoded sequences lists (processed data)\n","        self.encoded_sequences = []\n","        self.encoded_targets = []\n","        self.encoded_char_sequences = []\n","        # n=1 because first value is padding\n","        n_word = 1\n","        n_target = 1\n","        n_char = 1\n","        for line in train:\n","            sequence = []\n","            target = []\n","            chars = []\n","            for item in line.split('\\n'):\n","                if item != '':\n","                    word, label = item.split(' ')\n","\n","                    if self.word_vocab.get(word) is None:\n","                        self.word_vocab[word] = n_word\n","                        n_word += 1\n","                    if self.target_vocab.get(label) is None:\n","                        self.target_vocab[label] = n_target\n","                        n_target += 1\n","                    for char in word:\n","                        if self.char_vocab.get(char) is None:\n","                            self.char_vocab[char] = n_char\n","                            n_char += 1\n","                    sequence.append(self.word_vocab[word])\n","                    target.append(self.target_vocab[label])\n","                    chars.append([self.char_vocab[char] for char in word])\n","            self.encoded_sequences.append(sequence)\n","            self.encoded_targets.append(target)\n","            self.encoded_char_sequences.append(chars)\n","\n","    def __len__(self):\n","        return len(self.encoded_sequences)\n","\n","    def __getitem__(self, index):\n","        return {\n","            'data': self.encoded_sequences[index], # [1, 2, 3, 4, 6] len=5\n","            'char': self.encoded_char_sequences[index],# [[1,2,3], [4,5], [1,2], [2,6,5,4], []] len=5\n","            'target': self.encoded_targets[index], #  (1)\n","        }"],"metadata":{"id":"SI8UCZuy7hTK","executionInfo":{"status":"ok","timestamp":1678537625119,"user_tz":-300,"elapsed":299,"user":{"displayName":"Бот Nas","userId":"15068011115912218898"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["dataset = DatasetSeq(data_dir)"],"metadata":{"id":"dhJuBtoz7f43","executionInfo":{"status":"ok","timestamp":1678537630275,"user_tz":-300,"elapsed":1551,"user":{"displayName":"Бот Nas","userId":"15068011115912218898"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#padding\n","# seq1 = [1, 2, 3, 4]\n","# seq2 = [9, 7, 6, 4, 3, 7, 5]\n","# pad seq1 equal seq2\n","# seq1 = [1, 2, 3, 4, 0, 0, 0]\n","# concat(seq1, seq2) [[1, 2, 3, 4, 0, 0, 0],\n","#                     [9, 7, 6, 4, 3, 7, 5]]"],"metadata":{"id":"0zXXXYP37gFL","executionInfo":{"status":"ok","timestamp":1678537631810,"user_tz":-300,"elapsed":434,"user":{"displayName":"Бот Nas","userId":"15068011115912218898"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def collate_fn(input_data):\n","    data = []\n","    chars = []\n","    targets = []\n","    max_len = 0\n","    for item in input_data:\n","        if len(item['data']) > max_len:\n","            max_len = len(item['data'])\n","        data.append(torch.as_tensor(item['data']))\n","        chars.append(item['char'])\n","        targets.append(torch.as_tensor(item['target']))\n","    chars_seq = [[torch.as_tensor([0]) for _ in range(len(input_data))] for _ in range(max_len)]\n","    for j in range(len(input_data)):\n","        for i in range(max_len):\n","            if len(chars[j]) > i:\n","                chars_seq[i][j] = torch.as_tensor(chars[j][i])\n","    for j in range(max_len):\n","        chars_seq[j] = pad_sequence(chars_seq[j], batch_first=True, padding_value=0)\n","    data = pad_sequence(data, batch_first=True, padding_value=0)\n","    targets = pad_sequence(targets, batch_first=True, padding_value=0)\n","    return {'data': data, 'chars': chars_seq, 'target': targets}"],"metadata":{"id":"uPJauY4hAqJ6","executionInfo":{"status":"ok","timestamp":1678537636924,"user_tz":-300,"elapsed":279,"user":{"displayName":"Бот Nas","userId":"15068011115912218898"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class CharRNN(nn.Module):\n","    def __init__(self, vocab_size, emb_dim, hidden_dim):\n","        super().__init__()\n","        self.char_emb = nn.Embedding(vocab_size, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n","\n","    def forward(self, x):\n","        emb = self.char_emb(x) # B x T x Emb_dim\n","        _, out = self.rnn(emb)\n","        # _: B x T x Hidden \n","        # out: 1 x B x Hidden\n","\n","        return out.transpose(0, 1) # B x 1 x Hidden"],"metadata":{"id":"KTz2txO4LTZ3","executionInfo":{"status":"ok","timestamp":1678537640125,"user_tz":-300,"elapsed":14,"user":{"displayName":"Бот Nas","userId":"15068011115912218898"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# #TODO try to use other RNN archicetures, f.e. RNN and LSTM"],"metadata":{"id":"qML4tdrxhtzZ"}},{"cell_type":"code","source":["class RNNPredictor(nn.Module):\n","    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes,\n","                 char_vocab, char_emb, char_hidden):\n","        super().__init__()\n","        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n","        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n","        # batch_first = False: T x B x Vec\n","        # batch_first = True: B x T x Vec\n","        self.rnn = nn.RNN(emb_dim + char_hidden, hidden_dim, batch_first=True) \n","        self.clf = nn.Linear(hidden_dim, n_classes)\n","        self.do = nn.Dropout(0.1)\n","        self.hidden_dim = hidden_dim\n","        self.char_rnn = CharRNN(char_vocab, char_emb, char_hidden)\n","\n","    def forward(self, x, chars):\n","        emb = self.word_emb(x)\n","        char_features = [self.char_rnn(c.to(x.device)) for c in chars]\n","        char_features = torch.cat(char_features, dim=1) # конкатенация по времени B x T x Char_hid\n","        emb = torch.cat((emb, char_features), dim=-1) # конкатенация векторов\n","        hidden, _ = self.rnn(emb)\n","\n","        return self.clf(self.do(hidden))\n","\n","\n","class GRUPredictor(RNNPredictor):\n","    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes,\n","                 char_vocab, char_emb, char_hidden):\n","        super().__init__(vocab_size, emb_dim, hidden_dim, n_classes,\n","                 char_vocab, char_emb, char_hidden)\n","        self.rnn = nn.GRU(emb_dim + char_hidden, hidden_dim, batch_first=True) \n","\n","class LSTMPredictor(RNNPredictor):\n","    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes,\n","                 char_vocab, char_emb, char_hidden):\n","        super().__init__(vocab_size, emb_dim, hidden_dim, n_classes,\n","                 char_vocab, char_emb, char_hidden)\n","        self.rnn = nn.LSTM(emb_dim + char_hidden, hidden_dim, batch_first=True)         \n"],"metadata":{"id":"WBFZc1qY6HsC","executionInfo":{"status":"ok","timestamp":1678537643027,"user_tz":-300,"elapsed":263,"user":{"displayName":"Бот Nas","userId":"15068011115912218898"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#hyper params\n","vocab_size = len(dataset.word_vocab) + 1\n","n_classes = len(dataset.target_vocab) + 1\n","n_chars = len(dataset.char_vocab) + 1\n","#TODO try to use other model parameters\n","emb_dim = 256\n","hidden = 256\n","char_hid = 64\n","char_emb = 32\n","n_epochs = 10\n","batch_size = 64\n","cuda_device = 0\n","batch_size = 100\n","device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"],"metadata":{"id":"K_PACmDaH8Z7","executionInfo":{"status":"ok","timestamp":1678537646408,"user_tz":-300,"elapsed":276,"user":{"displayName":"Бот Nas","userId":"15068011115912218898"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["models = []\n","models.append(\n","     {'name':'GRU-model',\n","      'model':GRUPredictor(vocab_size, emb_dim, hidden, n_classes, n_chars, char_emb, char_hid).to(device),\n","      'loss_func':nn.CrossEntropyLoss()\n","            }\n",")\n","\n","models.append(\n","     {'name':'RNN-model',\n","      'model':RNNPredictor(vocab_size, emb_dim, hidden, n_classes, n_chars, char_emb, char_hid).to(device),\n","      'loss_func':nn.CrossEntropyLoss()\n","            }\n",")\n","\n","models.append(\n","     {'name':'LSTM-model',\n","      'model':LSTMPredictor(vocab_size, emb_dim, hidden, n_classes, n_chars, char_emb, char_hid).to(device),\n","      'loss_func':nn.CrossEntropyLoss()\n","            }\n",")\n","\n","\n","for mdl in models:\n","  mdl['optim'] = torch.optim.Adam(mdl['model'].parameters(), lr=0.001)\n","  mdl['model'].train()\n","  print (mdl['name'], mdl['model'])"],"metadata":{"id":"a4gX5zVDIZdu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678537652165,"user_tz":-300,"elapsed":3457,"user":{"displayName":"Бот Nas","userId":"15068011115912218898"}},"outputId":"6e97f640-7346-4508-98fb-df867be58b0a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["GRU-model GRUPredictor(\n","  (word_emb): Embedding(29588, 256)\n","  (rnn): GRU(320, 256, batch_first=True)\n","  (clf): Linear(in_features=256, out_features=18, bias=True)\n","  (do): Dropout(p=0.1, inplace=False)\n","  (char_rnn): CharRNN(\n","    (char_emb): Embedding(168, 32)\n","    (rnn): GRU(32, 64, batch_first=True)\n","  )\n",")\n","RNN-model RNNPredictor(\n","  (word_emb): Embedding(29588, 256)\n","  (rnn): RNN(320, 256, batch_first=True)\n","  (clf): Linear(in_features=256, out_features=18, bias=True)\n","  (do): Dropout(p=0.1, inplace=False)\n","  (char_rnn): CharRNN(\n","    (char_emb): Embedding(168, 32)\n","    (rnn): GRU(32, 64, batch_first=True)\n","  )\n",")\n","LSTM-model LSTMPredictor(\n","  (word_emb): Embedding(29588, 256)\n","  (rnn): LSTM(320, 256, batch_first=True)\n","  (clf): Linear(in_features=256, out_features=18, bias=True)\n","  (do): Dropout(p=0.1, inplace=False)\n","  (char_rnn): CharRNN(\n","    (char_emb): Embedding(168, 32)\n","    (rnn): GRU(32, 64, batch_first=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jVX0P0otIk4D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p_chekpoint = 100\n","\n","n_steps=len(dataset)//batch_size\n","\n","df_train_step = pd.DataFrame(columns=['epoch', 'step'], data=product(range(n_epochs), range(0, n_steps, p_chekpoint)))\n","#df_train_step.set_index(['epoch'], inplace=True)\n","df_train_step.set_index(['epoch', 'step'], inplace=True)\n","df_train_step\n","\n","for mdl in models:\n","  model = mdl['model']\n","  optim = mdl['optim']\n","  loss_func = mdl['loss_func']\n","\n","  mdl_name = mdl['name']\n","  #f_train_step[mdl_name+'_loss']=[None]*\n","  df_train_step.insert(df_train_step.shape[1], mdl_name+'_loss', None)\n","  df_train_step.insert(df_train_step.shape[1], mdl_name+'_time', None)\n","\n","  start = datetime.datetime.now()\n","  for epoch in range(n_epochs):\n","      dataloader = DataLoader(dataset, \n","                              batch_size, \n","                              shuffle=True, \n","                              collate_fn=collate_fn,\n","                              drop_last = True,\n","                              )\n","      for i, batch in enumerate(dataloader):\n","          optim.zero_grad()\n","\n","          predict = model(batch['data'].to(device), batch['chars'])\n","          loss = loss_func(predict.view(-1, n_classes),\n","                          batch['target'].to(device).view(-1), \n","                          )\n","          loss.backward()\n","          optim.step()\n","          if i % p_chekpoint == 0:\n","              clear_output(wait=True)\n","              df_train_step.loc[(epoch, i)][mdl_name+'_loss'] = loss.item()\n","              df_train_step.loc[(epoch, i)][mdl_name+'_time'] = datetime.datetime.now()-start\n","              display(df_train_step)\n","    \n","      torch.save(model.state_dict(), f'./rnn_chkpt__{mdl_name}_{epoch}.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"r2f3MATJ8GKb","executionInfo":{"status":"ok","timestamp":1678538434127,"user_tz":-300,"elapsed":777277,"user":{"displayName":"Бот Nas","userId":"15068011115912218898"}},"outputId":"40344343-3625-4a62-8916-a67dbd721da2"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["           GRU-model_loss  GRU-model_time RNN-model_loss  RNN-model_time  \\\n","epoch step                                                                 \n","0     0           2.91841  0:00:00.606839        2.85751  0:00:00.106013   \n","      100        0.254399  0:00:15.918162       0.218428  0:00:11.911622   \n","      200        0.152588  0:00:28.582636        0.16518  0:00:23.560976   \n","1     0          0.173208  0:00:30.282177       0.139539  0:00:24.837209   \n","      100        0.080576  0:00:42.311151       0.091557  0:00:36.408324   \n","      200        0.099854  0:00:54.568568       0.097285  0:00:49.874875   \n","2     0          0.103359  0:00:55.982431       0.116699  0:00:51.149632   \n","      100        0.087195  0:01:08.139684       0.075914  0:01:03.259655   \n","      200        0.091689  0:01:21.554053       0.090771  0:01:14.936527   \n","3     0          0.062941  0:01:23.070947       0.049428  0:01:16.075935   \n","      100        0.082032  0:01:35.033029       0.083367  0:01:28.140978   \n","      200        0.070778  0:01:46.579210       0.069913  0:01:39.614616   \n","4     0          0.061081  0:01:48.437638       0.063386  0:01:41.748715   \n","      100        0.044256  0:02:01.744874       0.054773  0:01:52.411320   \n","      200        0.047887  0:02:13.222335       0.075669  0:02:04.167507   \n","5     0          0.049025  0:02:15.209446       0.056311  0:02:05.818356   \n","      100        0.053295  0:02:26.001729       0.049458  0:02:18.565963   \n","      200        0.069362  0:02:38.171321       0.060969  0:02:30.574831   \n","6     0          0.051933  0:02:39.529897        0.04883  0:02:31.907278   \n","      100         0.04894  0:02:53.209965       0.034444  0:02:43.594069   \n","      200        0.054914  0:03:05.135728       0.039964  0:02:55.606326   \n","7     0          0.033258  0:03:06.537629       0.050332  0:02:57.453345   \n","      100        0.043488  0:03:18.167308       0.050696  0:03:10.033906   \n","      200        0.040558  0:03:31.626261       0.055361  0:03:21.611503   \n","8     0          0.030811  0:03:32.900911       0.026989  0:03:23.076434   \n","      100        0.027924  0:03:44.972718       0.043549  0:03:34.594979   \n","      200        0.028278  0:03:57.126885       0.044056  0:03:47.771042   \n","9     0          0.016806  0:03:58.531151       0.020999  0:03:49.248982   \n","      100         0.02015  0:04:10.341569       0.029294  0:04:01.500337   \n","      200        0.039928  0:04:23.445339       0.035728  0:04:12.852135   \n","\n","           LSTM-model_loss LSTM-model_time  \n","epoch step                                  \n","0     0           2.959137  0:00:00.124309  \n","      100         0.264779  0:00:12.193780  \n","      200         0.141908  0:00:25.141531  \n","1     0           0.161152  0:00:26.668119  \n","      100         0.094041  0:00:38.829182  \n","      200         0.115048  0:00:50.485189  \n","2     0            0.09718  0:00:51.840551  \n","      100         0.065279  0:01:04.948186  \n","      200         0.070495  0:01:15.901418  \n","3     0           0.067576  0:01:17.873162  \n","      100         0.065391  0:01:28.535305  \n","      200         0.068593  0:01:40.792067  \n","4     0           0.041244  0:01:42.086475  \n","      100         0.046238  0:01:55.689488  \n","      200         0.063995  0:02:07.383918  \n","5     0           0.049928  0:02:08.563027  \n","      100         0.050383  0:02:20.454139  \n","      200         0.054398  0:02:33.641816  \n","6     0           0.050439  0:02:35.271234  \n","      100         0.042497  0:02:46.776252  \n","      200         0.051575  0:02:58.989112  \n","7     0           0.031879  0:03:00.352764  \n","      100         0.028252  0:03:12.176687  \n","      200          0.03963  0:03:25.616094  \n","8     0           0.035446  0:03:27.010576  \n","      100         0.025644  0:03:38.944906  \n","      200         0.022891  0:03:50.505121  \n","9     0           0.031191  0:03:51.810413  \n","      100         0.027027  0:04:04.786134  \n","      200         0.028491  0:04:16.876221  "],"text/html":["\n","  <div id=\"df-8f350705-0147-4353-8f4f-d391d2c0f905\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>GRU-model_loss</th>\n","      <th>GRU-model_time</th>\n","      <th>RNN-model_loss</th>\n","      <th>RNN-model_time</th>\n","      <th>LSTM-model_loss</th>\n","      <th>LSTM-model_time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th>step</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">0</th>\n","      <th>0</th>\n","      <td>2.91841</td>\n","      <td>0:00:00.606839</td>\n","      <td>2.85751</td>\n","      <td>0:00:00.106013</td>\n","      <td>2.959137</td>\n","      <td>0:00:00.124309</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>0.254399</td>\n","      <td>0:00:15.918162</td>\n","      <td>0.218428</td>\n","      <td>0:00:11.911622</td>\n","      <td>0.264779</td>\n","      <td>0:00:12.193780</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>0.152588</td>\n","      <td>0:00:28.582636</td>\n","      <td>0.16518</td>\n","      <td>0:00:23.560976</td>\n","      <td>0.141908</td>\n","      <td>0:00:25.141531</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">1</th>\n","      <th>0</th>\n","      <td>0.173208</td>\n","      <td>0:00:30.282177</td>\n","      <td>0.139539</td>\n","      <td>0:00:24.837209</td>\n","      <td>0.161152</td>\n","      <td>0:00:26.668119</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>0.080576</td>\n","      <td>0:00:42.311151</td>\n","      <td>0.091557</td>\n","      <td>0:00:36.408324</td>\n","      <td>0.094041</td>\n","      <td>0:00:38.829182</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>0.099854</td>\n","      <td>0:00:54.568568</td>\n","      <td>0.097285</td>\n","      <td>0:00:49.874875</td>\n","      <td>0.115048</td>\n","      <td>0:00:50.485189</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">2</th>\n","      <th>0</th>\n","      <td>0.103359</td>\n","      <td>0:00:55.982431</td>\n","      <td>0.116699</td>\n","      <td>0:00:51.149632</td>\n","      <td>0.09718</td>\n","      <td>0:00:51.840551</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>0.087195</td>\n","      <td>0:01:08.139684</td>\n","      <td>0.075914</td>\n","      <td>0:01:03.259655</td>\n","      <td>0.065279</td>\n","      <td>0:01:04.948186</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>0.091689</td>\n","      <td>0:01:21.554053</td>\n","      <td>0.090771</td>\n","      <td>0:01:14.936527</td>\n","      <td>0.070495</td>\n","      <td>0:01:15.901418</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">3</th>\n","      <th>0</th>\n","      <td>0.062941</td>\n","      <td>0:01:23.070947</td>\n","      <td>0.049428</td>\n","      <td>0:01:16.075935</td>\n","      <td>0.067576</td>\n","      <td>0:01:17.873162</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>0.082032</td>\n","      <td>0:01:35.033029</td>\n","      <td>0.083367</td>\n","      <td>0:01:28.140978</td>\n","      <td>0.065391</td>\n","      <td>0:01:28.535305</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>0.070778</td>\n","      <td>0:01:46.579210</td>\n","      <td>0.069913</td>\n","      <td>0:01:39.614616</td>\n","      <td>0.068593</td>\n","      <td>0:01:40.792067</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">4</th>\n","      <th>0</th>\n","      <td>0.061081</td>\n","      <td>0:01:48.437638</td>\n","      <td>0.063386</td>\n","      <td>0:01:41.748715</td>\n","      <td>0.041244</td>\n","      <td>0:01:42.086475</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>0.044256</td>\n","      <td>0:02:01.744874</td>\n","      <td>0.054773</td>\n","      <td>0:01:52.411320</td>\n","      <td>0.046238</td>\n","      <td>0:01:55.689488</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>0.047887</td>\n","      <td>0:02:13.222335</td>\n","      <td>0.075669</td>\n","      <td>0:02:04.167507</td>\n","      <td>0.063995</td>\n","      <td>0:02:07.383918</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">5</th>\n","      <th>0</th>\n","      <td>0.049025</td>\n","      <td>0:02:15.209446</td>\n","      <td>0.056311</td>\n","      <td>0:02:05.818356</td>\n","      <td>0.049928</td>\n","      <td>0:02:08.563027</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>0.053295</td>\n","      <td>0:02:26.001729</td>\n","      <td>0.049458</td>\n","      <td>0:02:18.565963</td>\n","      <td>0.050383</td>\n","      <td>0:02:20.454139</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>0.069362</td>\n","      <td>0:02:38.171321</td>\n","      <td>0.060969</td>\n","      <td>0:02:30.574831</td>\n","      <td>0.054398</td>\n","      <td>0:02:33.641816</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">6</th>\n","      <th>0</th>\n","      <td>0.051933</td>\n","      <td>0:02:39.529897</td>\n","      <td>0.04883</td>\n","      <td>0:02:31.907278</td>\n","      <td>0.050439</td>\n","      <td>0:02:35.271234</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>0.04894</td>\n","      <td>0:02:53.209965</td>\n","      <td>0.034444</td>\n","      <td>0:02:43.594069</td>\n","      <td>0.042497</td>\n","      <td>0:02:46.776252</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>0.054914</td>\n","      <td>0:03:05.135728</td>\n","      <td>0.039964</td>\n","      <td>0:02:55.606326</td>\n","      <td>0.051575</td>\n","      <td>0:02:58.989112</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">7</th>\n","      <th>0</th>\n","      <td>0.033258</td>\n","      <td>0:03:06.537629</td>\n","      <td>0.050332</td>\n","      <td>0:02:57.453345</td>\n","      <td>0.031879</td>\n","      <td>0:03:00.352764</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>0.043488</td>\n","      <td>0:03:18.167308</td>\n","      <td>0.050696</td>\n","      <td>0:03:10.033906</td>\n","      <td>0.028252</td>\n","      <td>0:03:12.176687</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>0.040558</td>\n","      <td>0:03:31.626261</td>\n","      <td>0.055361</td>\n","      <td>0:03:21.611503</td>\n","      <td>0.03963</td>\n","      <td>0:03:25.616094</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">8</th>\n","      <th>0</th>\n","      <td>0.030811</td>\n","      <td>0:03:32.900911</td>\n","      <td>0.026989</td>\n","      <td>0:03:23.076434</td>\n","      <td>0.035446</td>\n","      <td>0:03:27.010576</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>0.027924</td>\n","      <td>0:03:44.972718</td>\n","      <td>0.043549</td>\n","      <td>0:03:34.594979</td>\n","      <td>0.025644</td>\n","      <td>0:03:38.944906</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>0.028278</td>\n","      <td>0:03:57.126885</td>\n","      <td>0.044056</td>\n","      <td>0:03:47.771042</td>\n","      <td>0.022891</td>\n","      <td>0:03:50.505121</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">9</th>\n","      <th>0</th>\n","      <td>0.016806</td>\n","      <td>0:03:58.531151</td>\n","      <td>0.020999</td>\n","      <td>0:03:49.248982</td>\n","      <td>0.031191</td>\n","      <td>0:03:51.810413</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>0.02015</td>\n","      <td>0:04:10.341569</td>\n","      <td>0.029294</td>\n","      <td>0:04:01.500337</td>\n","      <td>0.027027</td>\n","      <td>0:04:04.786134</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>0.039928</td>\n","      <td>0:04:23.445339</td>\n","      <td>0.035728</td>\n","      <td>0:04:12.852135</td>\n","      <td>0.028491</td>\n","      <td>0:04:16.876221</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f350705-0147-4353-8f4f-d391d2c0f905')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8f350705-0147-4353-8f4f-d391d2c0f905 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8f350705-0147-4353-8f4f-d391d2c0f905');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["#example\n","\n","phrase = 'I do love this magic neural networks !'\n","words = phrase.split(' ') \n","tokens = [dataset.word_vocab[w] for w in words]\n","chars = [torch.tensor([dataset.char_vocab[c] for c in w]).unsqueeze(0).to(device) for w in words]\n","\n","start = datetime.datetime.now()\n","for mdl in models:\n","  model = mdl['model']\n","  print(\"predict with \", mdl['name'])\n","  start = datetime.datetime.now()\n","  with torch.no_grad():\n","      model.eval()\n","      predict = model(torch.tensor(tokens).unsqueeze(0).to(device), chars) # 1 x T x N_classes\n","      labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n","      end = datetime.datetime.now() - start\n","\n","  target_labels = list(dataset.target_vocab.keys())\n","  print([target_labels[l-1] for l in labels])\n","  print(\"Predicted in\", datetime.datetime.now()-start, '\\n')"],"metadata":{"id":"9CljFAzIMMEW","colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1678538960223,"user_tz":-300,"elapsed":16,"user":{"displayName":"Бот Nas","userId":"15068011115912218898"}},"outputId":"cffd6c3b-e8d7-4233-d546-2663573fb4cd"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1bfb69997f99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'I do love this magic neural networks !'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-1bfb69997f99>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'I do love this magic neural networks !'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"74gggSX58Fe9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"-57Jq-CW8NmD"}}]}