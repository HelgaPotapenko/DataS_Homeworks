{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb8578a",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#написать-на-pytorch-глубокую-сеть,-проверить-работу-форвардпасса.\" data-toc-modified-id=\"написать-на-pytorch-глубокую-сеть,-проверить-работу-форвардпасса.-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>написать на pytorch глубокую сеть, проверить работу форвардпасса.</a></span></li><li><span><a href=\"#написать-адаптивный-оптимизатор\" data-toc-modified-id=\"написать-адаптивный-оптимизатор-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>написать адаптивный оптимизатор</a></span></li><li><span><a href=\"#решить-задачу-нахождения-корней-квадратного-уравнения-методом-градиентнго-спуска\" data-toc-modified-id=\"решить-задачу-нахождения-корней-квадратного-уравнения-методом-градиентнго-спуска-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>решить задачу нахождения корней квадратного уравнения методом градиентнго спуска</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1d65ba",
   "metadata": {},
   "source": [
    "Школа DataScientist, декабрь 2022, Андреева Ольга"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea43e66",
   "metadata": {},
   "source": [
    "# написать на pytorch глубокую сеть, проверить работу форвардпасса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda752f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f68b252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SomeDeepNN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.layers=[\n",
    "            {'model':nn.Linear(3, 5), 'activation':nn.ReLU()}\n",
    "            ,{'model':nn.BatchNorm1d(5, 5), 'activation':nn.ReLU()}\n",
    "            ,{'model':nn.Linear(5, 8), 'activation':nn.ReLU()}\n",
    "            ,{'model':nn.Linear(8, 8), 'activation':nn.Sigmoid()}\n",
    "            ,{'model':nn.BatchNorm1d(8, 8), 'activation':None}\n",
    "            ,{'model':nn.Linear(8, 8), 'activation':nn.ReLU()}\n",
    "            ,{'model':nn.Dropout(0.5), 'activation':None}\n",
    "            ,{'model':nn.BatchNorm1d(8, 8), 'activation':None}\n",
    "            ,{'model':nn.Linear(8, 3), 'activation':None}\n",
    "        ]\n",
    "      \n",
    "    def forward (self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer['model'](x)\n",
    "            x = layer['activation'](x) if layer['activation']!= None else x\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de966f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SomeDeepNN()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=SomeDeepNN()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95e09d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -22.6346,  -33.1693,  115.3141],\n",
       "        [  21.1943,  -17.0499,   -6.7838],\n",
       "        [ 141.5135,  -33.9041,   39.3967],\n",
       "        [ -21.4823, -201.3274,   35.6066],\n",
       "        [  -0.2814,  -83.4654,  -21.6383],\n",
       "        [  27.2823,  -37.5940,  102.3788],\n",
       "        [  23.1683,  116.4625,  -99.8064],\n",
       "        [ 274.9223,  -60.6725, -160.9105],\n",
       "        [ -71.0954,   71.4051,  -71.2489],\n",
       "        [-125.0409,  -73.1904, -143.8035]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch=torch.randn(10, 3)*100\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4709f94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3247,  0.2802,  0.2085],\n",
       "        [-0.3453,  0.2606,  0.1686],\n",
       "        [-0.3502,  0.2647,  0.1661],\n",
       "        [-0.3769,  0.2519,  0.3047],\n",
       "        [-0.3557,  0.2173,  0.2262],\n",
       "        [-0.3565,  0.2173,  0.2263],\n",
       "        [-0.3224,  0.2798,  0.2103],\n",
       "        [-0.3613,  0.2944,  0.2464],\n",
       "        [-0.3493,  0.2643,  0.1657],\n",
       "        [-0.3227,  0.2796,  0.2066]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc64284a",
   "metadata": {},
   "source": [
    "# написать адаптивный оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db9bbe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_backward(da, x):\n",
    "    sig = sigmoid(x)\n",
    "    \n",
    "    return da * sig * (1 - sig)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0., x)\n",
    "\n",
    "def relu_backward(da, x):\n",
    "    da = np.array(da, copy = True)\n",
    "    da[x <= 0] = 0;\n",
    "    return da;\n",
    "def mse_loss(t, y):\n",
    "    return (t - y) ** 2\n",
    "\n",
    "def d_mse_loss(t, y):\n",
    "    return 2 * (y - t) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "91e6bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self, n_inp, n_out, activation='sigmoid'):\n",
    "        self.w = np.random.randn(n_out, n_inp) * 0.1 #weigth\n",
    "        self.b = np.random.randn(n_out, 1) * 0.1     #bias\n",
    "        if activation == 'sigmoid':\n",
    "            self.activ = sigmoid\n",
    "        if activation == 'relu':\n",
    "            self.activ = relu\n",
    "        elif activation == 'None':\n",
    "            self.activ = None\n",
    "        else:\n",
    "            raise Exception(f'Unknown activation \"{activation}\"')\n",
    "        self._clear_state()\n",
    "\n",
    "    def _clear_state(self):\n",
    "        self.lin = None\n",
    "        self.inp = None\n",
    "        self.d_w = None\n",
    "        self.d_b = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.inp = x\n",
    "        self.lin = np.dot(self.w, x) + self.b\n",
    "        activ = self.activ(self.lin) if self.activ is not None else self.lin\n",
    "\n",
    "        return activ\n",
    "\n",
    "    def backward(self, grad): # grad = d L / d z    Dout \n",
    "        # grad * dz / d lin\n",
    "        if self.activ == sigmoid:\n",
    "            grad_lin = sigmoid_backward(grad, self.lin) \n",
    "        elif self.activ == relu:\n",
    "            grad_lin = relu_backward(grad, self.lin)\n",
    "        else:\n",
    "            grad_lin = grad\n",
    "        # grad_lin * d lin / d w \n",
    "        m = self.inp.shape[1]\n",
    "        self.d_w = np.dot(grad_lin, self.inp.T) / m    # d_in dOut\n",
    "        # grad_lin * d lin / d b \n",
    "        self.d_b = np.sum(grad_lin, axis=1, keepdims=True) / m\n",
    "\n",
    "        grad = np.dot(self.w.T, grad_lin)\n",
    "\n",
    "        return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "812a2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, arch: Tuple[Tuple[int, int]], activation):\n",
    "        self.layers = []\n",
    "        for i, p in enumerate(arch):\n",
    "            self.layers.append(\n",
    "                LinearLayer(p[0], p[1], \n",
    "                            activation=activation if i < len(arch)-1 else 'None')\n",
    "                )\n",
    "        self._clear_state()\n",
    "    \n",
    "    def _clear_state(self):\n",
    "        for l in self.layers:\n",
    "            l._clear_state()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad):\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad)\n",
    "        return grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6db85a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#для модели\n",
    "class RMSProp:\n",
    "    def __init__(self, model: LinearLayer, rho=0.99, lr=0.001):\n",
    "        self.lr = lr\n",
    "        self.rho = rho\n",
    "        self.model = model\n",
    "        self.vel_w=[]\n",
    "        self.vel_b=[]\n",
    "        for layer in self.model.layers:\n",
    "            self.vel_w.append(np.zeros_like(layer.w))\n",
    "            self.vel_b.append(np.zeros_like(layer.b))\n",
    "        \n",
    "    def step(self):\n",
    "        for i, layer in enumerate(self.model.layers):\n",
    "            \n",
    "            self.vel_w[i] = self.rho * self.vel_w[i] + (1 - self.rho) * layer.d_w**2\n",
    "            self.vel_b[i] = self.rho * self.vel_b[i] + (1 - self.rho) * layer.d_b**2\n",
    "            \n",
    "            layer.w -= layer.d_w * self.lr/(self.vel_w[i]**0/5)\n",
    "            layer.b -= layer.d_b * self.lr/(self.vel_b[i]**0/5)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for layer in self.model.layers:\n",
    "            layer.d_w = np.zeros_like(layer.d_w)\n",
    "            layer.d_b = np.zeros_like(layer.d_b)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "852ca67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.51086642 -0.01111784 -1.10098746 ...  0.95587133 -0.49462654\n",
      " -0.09591753]\n",
      "[2.30263182 0.02003808 1.23208786 ... 0.93360447 0.26456989 0.02911465]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.uniform(-2, 2, 20000)\n",
    "y = x**2 + np.random.randn()*0.01\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1a2791bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[1.00211988]] [[3.8820276]] [[1.02058841]] [[0.2736376]]\n",
      "1 [[1.01390391]] [[3.93306246]] [[1.02064509]] [[0.26853457]]\n",
      "2 [[1.01829736]] [[3.95359448]] [[1.02089674]] [[0.26756043]]\n",
      "3 [[1.01994691]] [[3.9660861]] [[1.02129997]] [[0.26763828]]\n",
      "4 [[1.02099506]] [[3.97497121]] [[1.0215066]] [[0.26781294]]\n",
      "5 [[1.02165287]] [[3.9815027]] [[1.02175126]] [[0.26802277]]\n",
      "6 [[1.02207596]] [[3.98659376]] [[1.02150682]] [[0.26828957]]\n",
      "7 [[1.0223604]] [[3.99068396]] [[1.02168595]] [[0.26830957]]\n",
      "8 [[1.02250317]] [[3.99379831]] [[1.02146034]] [[0.26817443]]\n",
      "9 [[1.02250598]] [[3.99616362]] [[1.02150512]] [[0.26801604]]\n",
      "10 [[1.02256296]] [[3.99783633]] [[1.02137432]] [[0.26794912]]\n",
      "11 [[1.02255175]] [[3.9992985]] [[1.02125841]] [[0.26781477]]\n",
      "12 [[1.02247241]] [[4.00057303]] [[1.02110578]] [[0.26774429]]\n",
      "13 [[1.02247787]] [[4.00178903]] [[1.0210335]] [[0.26767285]]\n",
      "14 [[1.02254958]] [[4.00265271]] [[1.02097313]] [[0.26755525]]\n",
      "15 [[1.02246601]] [[4.00357037]] [[1.02077145]] [[0.2674392]]\n",
      "16 [[1.02234314]] [[4.00434599]] [[1.02070213]] [[0.26729021]]\n",
      "17 [[1.02223022]] [[4.00508545]] [[1.02058391]] [[0.26715962]]\n",
      "18 [[1.02220054]] [[4.00570685]] [[1.02059495]] [[0.26705706]]\n",
      "19 [[1.02218296]] [[4.00635959]] [[1.0204945]] [[0.26693848]]\n"
     ]
    }
   ],
   "source": [
    "model = Model(((1, 100), (100, 1)), activation='relu')\n",
    "optim = RMSProp(model)\n",
    "for e in range(20):\n",
    "    for i, (val, t) in enumerate(zip(x, y)):\n",
    "        optim.zero_grad()\n",
    "        pred = model.forward(np.array([[val]]))\n",
    "        loss = mse_loss(t, pred)\n",
    "        grad = d_mse_loss(t, pred)\n",
    "        model.backward(grad)\n",
    "        optim.step()\n",
    "    print(e, model.forward([[1]]), model.forward([[2]]), model.forward([[-1]]), model.forward([[-0.5]]))       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06da910",
   "metadata": {},
   "source": [
    "# решить задачу нахождения корней квадратного уравнения методом градиентнго спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960fbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# Find the roots of square equation by gradient descent\n",
    "# x ** 2 - 6 * x + 4 = 0\n",
    "\n",
    "\n",
    "# посчитать производную от преобразованной функции\n",
    "# надо начать движение от начальной точки в направлении антиградиента с заданным шагом\n",
    "# x = x - lr * grad(x)\n",
    "# всегда ли сойдемся за приемлемое количество шагов?\n",
    "    # Нет. Не сойдемся, еслм неудачно выбрали начальную точку и lr. Ну или у уравнения может не быть корней.\n",
    "# важна ли начальная точка?\n",
    "    # Важна. \n",
    "    # Если инициализируемся в максимуме, grad(x)=0, x не меняется, вообще никуда не придём.\n",
    "    # Если начальная точка далеко от корня, grad(x) -> inf.\n",
    "        # При большом lr в этом случае мы на каждом шаге пролетаем мимо точки минимума и удаляемся от нее.\n",
    "        # При маленьком lr в этом случае улетает в небеса число шагов, за которое находим корень.    \n",
    "# как найти второй корень?\n",
    "    # Инициализироваться в другой точке.\n",
    "    # В случае с квадратным уравнением можно найти вершину параболы и выбрать новую точку отсчета относительно вершины.\n",
    "# как вляет ЛР?\n",
    "    # Если lr очень большое, можно никогда не попасть в точку минимума,\n",
    "    # т.к. будут слишком большие шаги, и от искомой точки мы будем удаляться, а не приближаться.\n",
    "    # с уменьшением lr возрастает точность попадания, но растет число шагов, и, соответственно, время, за которое находим корень  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a17307a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class equation:\n",
    "    def __init__ (self, cfs):\n",
    "        self.cfs=np.array(cfs) #коэффициенты квадратного уравнения\n",
    "        self.plnm=np.poly1d(cfs)\n",
    "        self.sq_plnm=np.polymul(self.plnm, self.plnm)  #функция, которую будем минимизировать - квадрат значения многочлена\n",
    "\n",
    "    def func(self, p_plnm, x): #резульат функции, которую будем минимизировать - квадрат значения многочлена\n",
    "        return (np.polyval(p_plnm, x))\n",
    "\n",
    "    def func_deriv(self, p_plnm, x): #прозводная функции, которую будем минимизировать\n",
    "        return np.polyval(np.polyder(p_plnm, m=1),x)\n",
    "\n",
    "    def gd(self, p_plnm, init_x, lr, steps, precision): #градиентный спуск\n",
    "        x=init_x\n",
    "        for step in range(steps):\n",
    "            df = self.func_deriv(p_plnm, x)\n",
    "#            if step%1000==0:\n",
    "#                print (step, x, df)\n",
    "            if abs(df) < precision:\n",
    "                if self.func(p_plnm, x)<self.func(p_plnm, x-precision): #проверка, что не попали в максимум\n",
    "                    print('found in', step, 'steps')\n",
    "                    return (x)\n",
    "            x = x - lr*df\n",
    " \n",
    "        if step >= steps-1:\n",
    "            print (step, x, df)\n",
    "            print('not found any root in', steps, 'steps')\n",
    "            return (None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e69433cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!\n",
      "found in 2677045 steps\n",
      "x = 5.236092977043281\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sq_eq = equation([1, -6, 4])\n",
    "x=sq_eq.gd(sq_eq.sq_plnm, 1000, 1e-7, 10000000, 0.001)\n",
    "print('x =', x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5448475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!\n",
      "found in 3196 steps\n",
      "!!!\n",
      "found in 3016 steps\n",
      "!!!\n",
      "found in 3022 steps\n",
      "x1 = 0.7639569884992341\n",
      "x2 = 5.236042987137295\n",
      "Wall time: 651 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##top=-sq_eq.cfs[1]/2*sq_eq.cfs[0]\n",
    "top=sq_eq.gd(sq_eq.plnm, 0, 0.001, 10000, 0.01)\n",
    "\n",
    "\n",
    "x1=sq_eq.gd(sq_eq.sq_plnm, top-1, 0.0001, 10000, 0.001)\n",
    "x2=sq_eq.gd(sq_eq.sq_plnm, top+1, 0.0001, 10000, 0.001)\n",
    "print('x1 =', x1)\n",
    "print('x2 =', x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff0868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
