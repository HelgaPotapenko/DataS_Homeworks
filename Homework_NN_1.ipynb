{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb8578a",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#написать-на-pytorch-глубокую-сеть,-проверить-работу-форвардпасса.\" data-toc-modified-id=\"написать-на-pytorch-глубокую-сеть,-проверить-работу-форвардпасса.-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>написать на pytorch глубокую сеть, проверить работу форвардпасса.</a></span></li><li><span><a href=\"#написать-адаптивный-оптимизатор\" data-toc-modified-id=\"написать-адаптивный-оптимизатор-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>написать адаптивный оптимизатор</a></span></li><li><span><a href=\"#решить-задачу-нахождения-корней-квадратного-уравнения-методом-градиентнго-спуска\" data-toc-modified-id=\"решить-задачу-нахождения-корней-квадратного-уравнения-методом-градиентнго-спуска-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>решить задачу нахождения корней квадратного уравнения методом градиентнго спуска</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1d65ba",
   "metadata": {},
   "source": [
    "Школа DataScientist, декабрь 2022, Андреева Ольга"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea43e66",
   "metadata": {},
   "source": [
    "# написать на pytorch глубокую сеть, проверить работу форвардпасса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bda752f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f68b252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SomeDeepNN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.layers=[\n",
    "            {'model':nn.Linear(3, 5), 'activation':nn.ReLU()}\n",
    "            ,{'model':nn.BatchNorm1d(5, 5), 'activation':nn.ReLU()}\n",
    "            ,{'model':nn.Linear(5, 8), 'activation':nn.ReLU()}\n",
    "            ,{'model':nn.Linear(8, 8), 'activation':nn.Sigmoid()}\n",
    "            ,{'model':nn.BatchNorm1d(8, 8), 'activation':None}\n",
    "            ,{'model':nn.Linear(8, 8), 'activation':nn.ReLU()}\n",
    "            ,{'model':nn.Dropout(0.5), 'activation':None}\n",
    "            ,{'model':nn.BatchNorm1d(8, 8), 'activation':None}\n",
    "            ,{'model':nn.Linear(8, 3), 'activation':None}\n",
    "        ]\n",
    "      \n",
    "    def forward (self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer['model'](x)\n",
    "            x = layer['activation'](x) if layer['activation']!= None else x\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de966f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SomeDeepNN()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=SomeDeepNN()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95e09d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 188.6986,  -42.3589,   50.8815],\n",
       "        [ -15.7684,    1.7608, -122.7787],\n",
       "        [  29.9381,   92.1885,  117.2309],\n",
       "        [  40.6160, -140.8805, -129.0985],\n",
       "        [ 197.3719,  -45.7335,   70.3666],\n",
       "        [  98.4731,  -33.6356,  -70.3143],\n",
       "        [ -47.7658,   92.0339,   39.7146],\n",
       "        [ 146.4833,  126.3035,  -51.2536],\n",
       "        [ -44.3214,  123.7859,    2.5476],\n",
       "        [-271.6638,   47.1077,   31.3210]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch=torch.randn(10, 3)*100\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4709f94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0105, -0.1834, -0.1137],\n",
       "        [-0.0073, -0.1855, -0.1114],\n",
       "        [-0.0331, -0.1867, -0.1193],\n",
       "        [-0.0052, -0.1868, -0.1098],\n",
       "        [-0.0076, -0.1852, -0.1116],\n",
       "        [-0.0238, -0.1834, -0.1131],\n",
       "        [-0.0279, -0.1810, -0.1157],\n",
       "        [-0.0247, -0.1833, -0.1133],\n",
       "        [-0.0336, -0.1868, -0.1194],\n",
       "        [-0.0277, -0.1813, -0.1158]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc64284a",
   "metadata": {},
   "source": [
    "# написать адаптивный оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd4753a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_backward(da, x):\n",
    "    sig = sigmoid(x)\n",
    "    \n",
    "    return da * sig * (1 - sig)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0., x)\n",
    "\n",
    "def relu_backward(da, x):\n",
    "    da = np.array(da, copy = True)\n",
    "    da[x <= 0] = 0;\n",
    "    return da;\n",
    "def mse_loss(t, y):\n",
    "    return (t - y) ** 2\n",
    "\n",
    "def d_mse_loss(t, y):\n",
    "    return 2 * (y - t) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91e6bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self, n_inp, n_out, activation='sigmoid'):\n",
    "        self.w = np.random.randn(n_out, n_inp) * 0.1 #weigth\n",
    "        self.b = np.random.randn(n_out, 1) * 0.1     #bias\n",
    "        if activation == 'sigmoid':\n",
    "            self.activ = sigmoid\n",
    "        if activation == 'relu':\n",
    "            self.activ = relu\n",
    "        elif activation == 'None':\n",
    "            self.activ = None\n",
    "        else:\n",
    "            raise Exception(f'Unknown activation \"{activation}\"')\n",
    "        self._clear_state()\n",
    "\n",
    "    def _clear_state(self):\n",
    "        self.lin = None\n",
    "        self.inp = None\n",
    "        self.d_w = None\n",
    "        self.d_b = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.inp = x\n",
    "        self.lin = np.dot(self.w, x) + self.b\n",
    "        activ = self.activ(self.lin) if self.activ is not None else self.lin\n",
    "\n",
    "        return activ\n",
    "\n",
    "    def backward(self, grad): # grad = d L / d z    Dout \n",
    "        # grad * dz / d lin\n",
    "        if self.activ == sigmoid:\n",
    "            grad_lin = sigmoid_backward(grad, self.lin) \n",
    "        elif self.activ == relu:\n",
    "            grad_lin = relu_backward(grad, self.lin)\n",
    "        else:\n",
    "            grad_lin = grad\n",
    "        # grad_lin * d lin / d w \n",
    "        m = self.inp.shape[1]\n",
    "        self.d_w = np.dot(grad_lin, self.inp.T) / m    # d_in dOut\n",
    "        # grad_lin * d lin / d b \n",
    "        self.d_b = np.sum(grad_lin, axis=1, keepdims=True) / m\n",
    "\n",
    "        grad = np.dot(self.w.T, grad_lin)\n",
    "\n",
    "        return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f80cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, arch: Tuple[Tuple[int, int]], activation):\n",
    "        self.layers = []\n",
    "        for i, p in enumerate(arch):\n",
    "            self.layers.append(\n",
    "                LinearLayer(p[0], p[1], \n",
    "                            activation=activation if i < len(arch)-1 else 'None')\n",
    "                )\n",
    "        self._clear_state()\n",
    "    \n",
    "    def _clear_state(self):\n",
    "        for l in self.layers:\n",
    "            l._clear_state()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad):\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad)\n",
    "        return grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "128876a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#для модели\n",
    "class RMSProp:\n",
    "    def __init__(self, model: LinearLayer, rho=0.99, lr=0.001):\n",
    "        self.lr = lr\n",
    "        self.rho = rho\n",
    "        self.model = model\n",
    "        self.vel_w=[]\n",
    "        self.vel_b=[]\n",
    "        for layer in self.model.layers:\n",
    "            self.vel_w.append(np.zeros_like(layer.w))\n",
    "            self.vel_b.append(np.zeros_like(layer.b))\n",
    "        \n",
    "    def step(self):\n",
    "        for i, layer in enumerate(self.model.layers):\n",
    "            \n",
    "            self.vel_w[i] = self.rho * self.vel_w[i] + (1 - self.rho) * layer.d_w**2\n",
    "            self.vel_b[i] = self.rho * self.vel_b[i] + (1 - self.rho) * layer.d_b**2\n",
    "            \n",
    "            layer.w -= layer.d_w * self.lr/(self.vel_w[i]**0/5)\n",
    "            layer.b -= layer.d_b * self.lr/(self.vel_b[i]**0/5)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for layer in self.model.layers:\n",
    "            layer.d_w = np.zeros_like(layer.d_w)\n",
    "            layer.d_b = np.zeros_like(layer.d_b)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e617e486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.03799105  1.87060634 -0.68860144 ...  0.2346453   0.03657749\n",
      "  1.67475985]\n",
      "[1.08881509 3.51055773 0.48556161 ... 0.06644808 0.01272758 2.81621021]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.uniform(-2, 2, 20000)\n",
    "y = x**2 + np.random.randn()*0.01\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "84788612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[0.98517878]] [[3.86524164]] [[0.99044424]] [[0.26625722]]\n",
      "1 [[1.0069398]] [[3.92873267]] [[1.00440806]] [[0.25963116]]\n",
      "2 [[1.01451602]] [[3.95391384]] [[1.0144683]] [[0.26227908]]\n",
      "3 [[1.01790828]] [[3.96678813]] [[1.01274495]] [[0.26277565]]\n",
      "4 [[1.01923901]] [[3.9744744]] [[1.01084439]] [[0.26261078]]\n",
      "5 [[1.02056346]] [[3.97971381]] [[1.00947312]] [[0.26230627]]\n",
      "6 [[1.02082732]] [[3.98307646]] [[1.00842799]] [[0.26203254]]\n",
      "7 [[1.02131839]] [[3.98576036]] [[1.00755432]] [[0.26176604]]\n",
      "8 [[1.02157074]] [[3.98776906]] [[1.00668923]] [[0.26153397]]\n",
      "9 [[1.02190264]] [[3.98953573]] [[1.00576562]] [[0.26137117]]\n",
      "10 [[1.02194349]] [[3.9908611]] [[1.00507554]] [[0.26119673]]\n",
      "11 [[1.02220317]] [[3.99189321]] [[1.00434805]] [[0.26109218]]\n",
      "12 [[1.02215024]] [[3.99291003]] [[1.00372964]] [[0.26096549]]\n",
      "13 [[1.02233486]] [[3.99400428]] [[1.00314233]] [[0.26081377]]\n",
      "14 [[1.02200045]] [[3.99501536]] [[1.00259559]] [[0.26083529]]\n",
      "15 [[1.02222793]] [[3.99592813]] [[1.00196812]] [[0.26100221]]\n",
      "16 [[1.02279202]] [[3.99573928]] [[1.0018299]] [[0.261169]]\n",
      "17 [[1.02211048]] [[3.99628561]] [[1.00234674]] [[0.26129163]]\n",
      "18 [[1.0214924]] [[3.99678004]] [[1.00272773]] [[0.26136526]]\n",
      "19 [[1.02086857]] [[3.9971882]] [[1.00310112]] [[0.26141918]]\n"
     ]
    }
   ],
   "source": [
    "model = Model(((1, 100), (100, 1)), activation='relu')\n",
    "optim = RMSProp(model)\n",
    "for e in range(20):\n",
    "    for i, (val, t) in enumerate(zip(x, y)):\n",
    "        optim.zero_grad()\n",
    "        pred = model.forward(np.array([[val]]))\n",
    "        loss = mse_loss(t, pred)\n",
    "        grad = d_mse_loss(t, pred)\n",
    "        model.backward(grad)\n",
    "        optim.step()\n",
    "    print(e, model.forward([[1]]), model.forward([[2]]), model.forward([[-1]]), model.forward([[-0.5]]))       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c303d75",
   "metadata": {},
   "source": [
    "# решить задачу нахождения корней квадратного уравнения методом градиентнго спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a67379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# Find the roots of square equation by gradient descent\n",
    "# x ** 2 - 6 * x + 4 = 0\n",
    "\n",
    "\n",
    "# посчитать производную от преобразованной функции\n",
    "# надо начать движение от начальной точки в направлении антиградиента с заданным шагом\n",
    "# x = x - lr * grad(x)\n",
    "# всегда ли сойдемся за приемлемое количество шагов?\n",
    "    # Нет. Не сойдемся, еслм неудачно выбрали начальную точку и lr. Ну или у уравнения может не быть корней.\n",
    "# важна ли начальная точка?\n",
    "    # Важна. \n",
    "    # Если инициализируемся в максимуме, grad(x)=0, x не меняется, вообще никуда не придём.\n",
    "    # Если начальная точка далеко от корня, grad(x) -> inf.\n",
    "        # При большом lr в этом случае мы на каждом шаге пролетаем мимо точки минимума и удаляемся от нее.\n",
    "        # При маленьком lr в этом случае улетает в небеса число шагов, за которое находим корень.    \n",
    "# как найти второй корень?\n",
    "    # Инициализироваться в другой точке.\n",
    "    # В случае с квадратным уравнением можно найти вершину параболы и выбрать новую точку отсчета относительно вершины.\n",
    "# как вляет ЛР?\n",
    "    # Если lr очень большое, можно никогда не попасть в точку минимума,\n",
    "    # т.к. будут слишком большие шаги, и от искомой точки мы будем удаляться, а не приближаться.\n",
    "    # с уменьшением lr возрастает точность попадания, но растет число шагов, и, соответственно, время, за которое находим корень  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c487ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class equation:\n",
    "    def __init__ (self, cfs):\n",
    "        self.cfs=np.array(cfs) #коэффициенты квадратного уравнения\n",
    "        self.plnm=np.poly1d(cfs)\n",
    "        self.sq_plnm=np.polymul(self.plnm, self.plnm)  #функция, которую будем минимизировать - квадрат значения многочлена\n",
    "\n",
    "    def func(self, p_plnm, x): #резульат функции, которую будем минимизировать - квадрат значения многочлена\n",
    "        return (np.polyval(p_plnm, x))\n",
    "\n",
    "    def func_deriv(self, p_plnm, x): #прозводная функции, которую будем минимизировать\n",
    "        return np.polyval(np.polyder(p_plnm, m=1),x)\n",
    "\n",
    "    def gd(self, p_plnm, init_x, lr, steps, precision): #градиентный спуск\n",
    "        x=init_x\n",
    "        for step in range(steps):\n",
    "            df = self.func_deriv(p_plnm, x)\n",
    "#            if step%1000==0:\n",
    "#                print (step, x, df)\n",
    "            if abs(df) < precision:\n",
    "                if self.func(p_plnm, x)<self.func(p_plnm, x-precision): #проверка, что не попали в максимум\n",
    "                    print('found in', step, 'steps')\n",
    "                    return (x)\n",
    "            x = x - lr*df\n",
    " \n",
    "        if step >= steps-1:\n",
    "            print (step, x, df)\n",
    "            print('not found any root in', steps, 'steps')\n",
    "            return (None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac07d22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in 2677045 steps\n",
      "x = 5.236092977043281\n",
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sq_eq = equation([1, -6, 4])\n",
    "x=sq_eq.gd(sq_eq.sq_plnm, 1000, 1e-7, 10000000, 0.001)\n",
    "print('x =', x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e952083d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in 3196 steps\n",
      "found in 3016 steps\n",
      "found in 3022 steps\n",
      "x1 = 0.7639569884992341\n",
      "x2 = 5.236042987137295\n",
      "Wall time: 625 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##top=-sq_eq.cfs[1]/2*sq_eq.cfs[0]\n",
    "top=sq_eq.gd(sq_eq.plnm, 0, 0.001, 10000, 0.01)\n",
    "\n",
    "\n",
    "x1=sq_eq.gd(sq_eq.sq_plnm, top-1, 0.0001, 10000, 0.001)\n",
    "x2=sq_eq.gd(sq_eq.sq_plnm, top+1, 0.0001, 10000, 0.001)\n",
    "print('x1 =', x1)\n",
    "print('x2 =', x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086783e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
